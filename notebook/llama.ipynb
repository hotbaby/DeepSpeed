{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dataclasses\n",
    "from llama import ModelArgs\n",
    "from llama import Transformer, TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model ...\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"dim\": 4096,            # hidden dim 隐藏层维度\n",
    "    \"n_layers\": 32,         # transformer block层数\n",
    "    \"n_heads\": 32,          # 自注意力head数量\n",
    "    \"vocab_size\": 32000,    # 词表大小\n",
    "    \"multiple_of\": 256,     # 用于计算transformer block 前向传播隐藏层维度\n",
    "    \"norm_eps\": 1e-06,\n",
    "}\n",
    "model_args = ModelArgs(**params)\n",
    "\n",
    "print(\"init model ...\")\n",
    "llama_model = Transformer(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_param_num(module: nn.Module):\n",
    "    return sum([p.numel() for p in module.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (tok_embeddings): Embedding(32000, 4096)\n",
      "  (layers): ModuleList(\n",
      "    (0-31): 32 x TransformerBlock(\n",
      "      (attention): Attention(\n",
      "        (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "        (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "      )\n",
      "      (attention_norm): RMSNorm()\n",
      "      (ffn_norm): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (norm): RMSNorm()\n",
      "  (output): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(llama_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed params:\t 131,072,000\n",
      "layers params:\t 6,476,267,520\n",
      "norm params:\t 4,096\n",
      "output params:\t 131,072,000\n",
      "total params:\t 6,738,415,616\n"
     ]
    }
   ],
   "source": [
    "print(f\"embed params:\\t {module_param_num(llama_model.tok_embeddings):,d}\")\n",
    "print(f\"layers params:\\t {module_param_num(llama_model.layers):,d}\")\n",
    "print(f\"norm params:\\t {module_param_num(llama_model.norm):,d}\")\n",
    "print(f\"output params:\\t {module_param_num(llama_model.output):,d}\")\n",
    "print(f\"total params:\\t {module_param_num(llama_model):,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {\n",
      "    \"dim\": 4096,\n",
      "    \"n_layers\": 32,\n",
      "    \"n_heads\": 32,\n",
      "    \"vocab_size\": 32000,\n",
      "    \"multiple_of\": 256,\n",
      "    \"norm_eps\": 1e-06,\n",
      "    \"max_batch_size\": 32,\n",
      "    \"max_seq_len\": 2048\n",
      "}\n",
      "total params: 6,738,415,616\n"
     ]
    }
   ],
   "source": [
    "print(f\"config: {json.dumps(dataclasses.asdict(model_args), ensure_ascii=False, indent=4)}\")\n",
    "print(f\"total params: {llama_model_params(model_args):,d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a26945acae1dbe174fa8a7f2737f59bcc9ca988f8fc990f33e458e609cda8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
